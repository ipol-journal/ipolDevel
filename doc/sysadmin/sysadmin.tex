% Instructions to modify this document:
% * Remember to ALWAYS execute "git pull" BEFORE any commit you make!
% * Use the \ToDo{...} command to remark tasks which still need to be done. Add your name in the comment.
% * Use the \input{file.tex} command to split the document into several parts
% * Do not change the current LaTeX coding style to yours. The style and format should be homogeneous along sections.

% To convert .dia diagrams into PDF:
% 1) Create the diagram with dia
% 2) Export it as .eps
% 3) use epstopdf to convert to PDF
%
% Editing SVG files and exporting them to PDF with Inkscape is admitted too.
% Remember to keep a copy of the editable file (.dia or .svg files).


\documentclass[a4paper,12pt]{article}

\usepackage[utf8]{inputenc}
\usepackage{amsmath,graphicx}
\usepackage{bm}
\usepackage{amssymb}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{subfigure}
\usepackage{ifpdf}
\usepackage{url}
\usepackage{color}
\usepackage[hidelinks]{hyperref}
\usepackage{multirow}
\usepackage{datetime}
\usepackage{comment}
\usepackage{float} % To put figures in their exact place with \begin{figure}[H]
\usepackage{longtable}
\usepackage{tabularx}
\usepackage{listings}
\usepackage{xcolor}
\usepackage{parskip} % Avoid automatic indentation of every paragraph



% Definitions and commands
\def \np{\vskip 0.25 cm}
\def \ap{\vskip 0.15 cm}

\lstset{language=Bash, basicstyle=\color{gray}}

\newcommand{\ToDo}[1]{\textcolor{magenta}{\textbf{[ToDo]} \textbf{#1}}}
\newcommand{\miguel}[1]{\textcolor{magenta}{\textbf{[Miguel]} \textbf{#1}}}


\begin{document}

\begin{titlepage}

\begin{center}
\vspace*{-1in}

\vspace*{0.6in}
\begin{Large}
\textbf{The IPOL Demo System 2.0 \\System Administration Documentation} \\
\end{Large}

\vspace*{0.6in}

\small{Compiled on \today\ at \currenttime}

\vspace*{0.6in}
\rule{80mm}{0.1mm}\\
\vspace*{0.1in}
\end{center}

\end{titlepage}

This document contains System Administration documentation for the IPOL Demo System 2.0.
\vspace*{0.6in}


%\maketitle
\newpage

\tableofcontents
\newpage
% \listoffigures
% \newpage

\section{Obtaining the source code of the demo system}
Use git to get the IPOL sources. The ipolDevel folder MUST be in your home directory.
\begin{verbatim}
~$ cd
~$ git clone https://github.com/mcolom/ipolDevel.git
~$ cd ipolDevel/
~/ipolDevel$
\end{verbatim}

The production servers use the {\tt master} branch, but for development the {\tt devel} branch MUST be used, never master.
\begin{verbatim}
git checkout devel
\end{verbatim}


\section{Crontab scripts}
The system needs to periodically execute administration script, to create backups, clean up old data, or to perform continuous integration tests. This section describes these scripts.

To modify the crontab configuration, the command is {\tt crontab -e}. The format of the crontab lines is: minute (m), hour (h), day of month (dom), month (mon), and day of week (dow), or use '*' in these fields (for 'any').

\begin{itemize}
    \item \textbf{Backups}: they are done by this script: {\tt ipolDevel/sysadmin/backup.sh}. See Sec.~\ref{sec:backups}.
    
    \item \textbf{Backup sync}: the script {\tt ipolDevel/sysadmin/backup\_sync.sh} synchronizes backups from ipolcore to DR1. See Sec.~\ref{sec:backups}.

We use the following line to run the backup script once per week after a backup has been done at 3:00h:

    {\tt 0 3 * * 2 /home/ipol/ipolDevel/sysadmin/backup\_sync.sh}
    
    \item \textbf{Cleanup}: the script {\tt ipolDevel/sysadmin/cleanup.sh} does a cleanup of all temporary files older than one month.

    {\tt 0 5 * * 1 /home/ipol/ipolDevel/sysadmin/cleanup.sh}

    \item \textbf{PyLint report}: the script {\tt ipolDevel/ci\_tests/pylint.sh} uses PyLint to create code quality reports. It executes weekly in the integration server and sends an email to the addresses in the file {\tt send\_to.txt}

    {\tt 0 15 * * 2 /home/ipol/ipolDevel/ci\_tests/pylint.sh}

    \item \textbf{pdflatex report}: the script {\tt ipolDevel/ci\_tests/pdflatex.sh} checks if the Latex documentation of the project compiles and sends and email otherwise.

    {\tt 0 15 * * 2 sudo -u ipol /home/ipol/ipolDevel/ci\_tests/pdflatex.sh}

    \item \textbf{Reboot}: the script {\tt ipolDevel/sysadmin/on\_reboot.sh} starts all IPOL modules, nginx and the shared folder in the production machines, and sends a warning email. To execute it, the following line needs to be added with {\tt crontab -e} as root.

    {\tt @reboot ipolDevel/sysadmin/on\_reboot.sh}
\end{itemize}

\section{GitHub deploy key}
The IPOL GitHub repository might be private. Thus, is any server needs to obtain the complete source code of the demo system, a \emph{deploy key} is needed. The deploy key is added to the GitHub configuration and each server needs to get the sources using the deploy key.

For example:

\begin{verbatim}
ipol@smartalgo:~/ipolDevel$ cat ~/.ssh/config
host github_deploy
      hostname github.com
      user git
      identityfile ~/.ssh/id_rsa_deploy
\end{verbatim}

\vspace{0.15cm}

\begin{verbatim}
ipol@smartalgo:~/ipolDevel$ cat .git/config
[core]
	repositoryformatversion = 0
	filemode = true
	bare = false
	logallrefupdates = true
[remote "origin"]
	#url = https://github.com/mcolom/ipolDevel
	url = git@github_deploy:mcolom/ipolDevel.git
	fetch = +refs/heads/*:refs/remotes/origin/*
[branch "master"]
	remote = origin
	merge = refs/heads/master
\end{verbatim}

We use the host \emph{github\_deploy} in order to pick the deploy key in the SSH connection.

\section{Setup of a new machine}
When a new machine is added to the IPOL infrastructure, the following needs to be done:

- Install a Debian Stable distribution. That is very important: the minimal requirement is Debian Stable, not any Debian distribution below or over Stable.

- Create the {\tt ipol} user in a new machine: {\tt adduser ipol}

- Install bash-completion {\tt apt install bash-completion}

- Configure the SSH server to allow only access with public key and not with password. Set the following in /etc/ssh/sshd\_config:

{\tt PubkeyAuthentication yes}

And restart the SSH server with {\tt service ssh restart}

- Install unattended-upgrades and apt-listchanges: {\tt apt install unattended-upgrades apt-listchanges}

And edit /etc/apt/apt.conf.d/50unattended-upgrades, at least uncomment the following lines:
\begin{verbatim}
  Unattended-Upgrade::Origins-Pattern {
    "o=Debian,a=stable";
    "o=Debian,a=stable-updates";
  };
\end{verbatim}

- Configuration of the email server to be able to send emails form any of the IPOL servers: configure with {\tt dpkg-reconfigure exim4-config} and be sure to choose the option to send email on the Internet, not local.

Install mail with {\tt apt install mailutils}

It is important to set the hostname with the real Internet address in {\tt /etc/hosts} to send the emails outside. For example, for \emph{our} ipolcore machine, the configuration is the following (please check your actual addresses, do not simply copy those!):

\begin{verbatim}
5.196.85.84             ipolcore.ipol.im     ipolcore
2001:41d0:a:7654::1     ipolcore.ipol.im     ipolcore
\end{verbatim}

Example of sending an email: {\tt cat email.txt | mail -s "This is the subject" john.doe@example.com,banania.guy@example.com}

To clone the ipolDevel repository in a new machine, the SSH access must be configured with the RSA deploy key so ssh can use it to clone the repository. This allows to clone the repository even if it eventually becomes private.
%
The deploy private key must be copied to {\tt .ssh/id\_rsa\_deploy} and the following lines need to be added to .ssh/config:

\begin{verbatim}
host github_deploy
      hostname github.com
      user git
      identityfile ~/.ssh/id_rsa_deploy
\end{verbatim}

Then, clone the repository with {\tt git clone git@github\_deploy:mcolom/ipolDevel.git}

In {\tt ipolDevel/sysadmin/install\_packages/} there is a script that needs to be run with {\tt sudo ./install\_dist\_packages.sh}. It will install all required Debian packages listed in apt\_requirements.txt.

If the python line {\tt import mimetypes; print(mimetypes.guess\_extension("image/webp"))} prints None, then add the {\tt image/webp webp} to the file {\tt /usr/local/etc/mime.types}.

\subsection{External repositories}
Some packages as for example Intel's IPP are not directly in the Debian Stable distribution and therefore they need to be added to APT manually. Normally it implies just adding the repository's \emph{.list} file to {\tt /etc/apt/sources.list.d}.
For Intel IPP, it is described in their website\footnote{\url{https://software.intel.com/en-us/articles/installing-intel-free-libs-and-python-apt-repo}}.

\subsection{IPv6 in OVH}
Some of the OS images for the dedicated servers in OVH do not include the IPv6 configuration and it needs to be added manually to {\tt /etc/network/interfaces}.
For example, for a machine with {\tt IPv4=5.196.85.84} and {\tt IPv6=2001:41d0:a:7654::1}, the following configuration needs to be added:

\begin{verbatim}
auto eno0
iface eno0 inet static
    address 5.196.85.84
    netmask 255.255.255.0
    network 5.196.85.0
    broadcast 5.196.85.255
    gateway 5.196.85.254

iface eno0 inet6 static
    address 2001:41d0:a:7654::1
    netmask 64
    dns-nameservers 2001:41d0:3:163::1
    post-up /sbin/ip -family inet6 route add 2001:41d0:a:76ff:ff:ff:ff:ff dev eno0
    post-up /sbin/ip -family inet6 route add default via 2001:41d0:a:76ff:ff:ff:ff:ff
    pre-down /sbin/ip -family inet6 route del default via 2001:41d0:a:76ff:ff:ff:ff:ff
    pre-down /sbin/ip -family inet6 route del 2001:41d0:a:76ff:ff:ff:ff:ff dev eno0
\end{verbatim}

Note that depending on the kernel, the network interface might be named {\tt eno0}, {\tt eth0}, or any other name.


\begin{comment}
\subsection{Manual configurations}
Some of the installed packages need manual changes in their configuration.

- Octave: edit the file {\tt /usr/share/octave/site/m/startup/octaverc} and {\tt add pkg load image}.
\end{comment}


\section{Nginx}

\subsection{Installation}

\begin{enumerate}
\item Debian

\begin{enumerate}
    \item Uninstall previous nginx version
    \begin{verbatim}[language=Bash]
	{prod} ~/ipolDevel$ apt remove nginx-common
    \end{verbatim}

    \item Update repositories
    \begin{verbatim}[language=Bash]
    {prod} ~/ipolDevel$ apt update
    \end{verbatim}

    \item Install nginx
    \begin{verbatim}[language=Bash]
    {prod} ~/ipolDevel$ apt install nginx
    \end{verbatim}
    \end{enumerate}    
\end{enumerate}

\subsection{Configuration}

Copy your configurations to {\tt /etc/nginx/sites-enabled} and leave {\tt /etc/nginx/sites-available} as a reference that will be updated by apt.

\begin{enumerate}
    \item Edit the config file /etc/nginx/nginx.conf, adding the following include at the end of the http subsection:
    \begin{verbatim}[language=Bash]
    include /etc/nginx/sites-enabled/*;
    \end{verbatim}
    \item Edit the site configuration file: sites-enabled/default, configuring the subsections:
    \begin{enumerate}
    \item Upstream
    \begin{enumerate}
    \item Upstream name. E.g.: ipol\_webapp\_server
    \item Gunicorn socket file absolute location.
    \end{enumerate}
    \item Server
    \begin{enumerate}
    \item Listening port. The port to serve the site with static files. E.g.: 8000
    \item Server name. E.g.: ipolcore.ipol.im
    \item A resolver, necessary to set variables in the configuration for Debian distributions.
    \begin{verbatim}[language=Bash]
    resolver 213.186.33.99;
    \end{verbatim}
    \item Increase timeout for send and receive requests.
    \begin{verbatim}[language=Bash]
    proxy_send_timeout	600;
    proxy_read_timeout	600;
    send_timeout		600;
    \end{verbatim}
    \item Access log absolute location.
    \item A location for each module.
    \begin{verbatim}[language=Bash]
    location /api/<module>/ {
      rewrite ^/api/<module>/(.*) /$1 break;
      proxy_pass  http://$host:<port>;
    }
    \end{verbatim}
    \item Static files absolute location.
    \begin{verbatim}[language=Bash]
    location /cp/static/ {
      alias  /home/<user>/IPOLWEBAPP_STATIC/;
    }
    \end{verbatim}
    \item Proxy pass, using upstream name configured previously.
    E.g.:
    \begin{verbatim}[language=Bash]
    proxy_pass http://ipol_webapp_server;
    \end{verbatim}

    \end{enumerate}
    \end{enumerate}
\end{enumerate}

As a good practice we enable Nginx gzip compression for static files. An example of this configuration part is located at the project repository in the nginx.conf file under the sysadmin folder.

\subsubsection{SSL on production}
The files included in the snippets will configure SSL. Test with {\tt nginx -t} that your configuration is correct. Indeed, you will have to copy the following files:
\begin{itemize}
    \item /etc/ssl/certs/ipolcore\_ipol\_im\_chain.crt
    \item /etc/ssl/private/ipolcore.key
    \item /etc/ssl/certs/dhparam.pem
\end{itemize}



\subsubsection{SSL on the integration}
For the integration server we use certbot to generate and automatically renew SSL certificates.

\begin{enumerate}
  \item Install certbot and its dependencies
  \begin{verbatim}[language=Bash]
  sudo apt update
  sudo apt install python3-acme python3-certbot python3-mock \
  python3-openssl python3-pkg-resources python3-pyparsing \
  python3-zope.interface
  sudo apt install python3-certbot-nginx
  \end{verbatim}
  \item Generate certificate
  \begin{verbatim}[language=Bash]
  sudo certbot certonly --nginx -d integration.ipol.im
  \end{verbatim}
  \item Configure Nginx. Add to default configuration file.
  \begin{verbatim}[language=Bash]
  # Enable SSL
  listen *:443 ssl http2 default_server;
  listen [::]:443 ssl http2 default_server;
  include snippets/certificate.conf;
  include snippets/ssl-params.conf;
  include /etc/letsencrypt/options-ssl-nginx.conf;
  \end{verbatim}
  \item Validate configuration and restart Nginx
  \begin{verbatim}[language=Bash]
  sudo nginx -t && sudo nginx -s reload
  \end{verbatim}
  \item Create cronjob to renew the certificate periodically. This should be done on the sudo user crontab.
  \begin{verbatim}[language=Bash]
  0 12 * * * /usr/bin/certbot renew --quiet
  \end{verbatim}

\end{enumerate}

\subsubsection{Private demos}
\begin{enumerate}
    \item Add authentication for demos. Only in the machine which serves the static files of the demo, of course.
    \begin{enumerate}
    \item Create subfolder .passwd in /etc/nginx
    \begin{verbatim}[language=Bash]
    mkdir /etc/nginx/.passwd
    \end{verbatim}
    \item Install apache2-utils
    \begin{verbatim}[language=Bash]
    sudo apt install apache2-utils
    \end{verbatim}
    \item Create username and password with htpasswd
    \begin{verbatim}[language=Bash]
     sudo htpasswd -c /etc/nginx/.passwd/company company
    \end{verbatim}
    \item Edit the {\tt default} file to add authentication, e.g. add authentication to all the demos which its id starts with 33333999
    \begin{verbatim}[language=Bash]
    location /demo/clientApp/demo.html {
      if ($args ~ ".*id=33333999\d*") {
	error_page 418 = @companyPasswd;
	return 418;
      }
      proxy_pass  http://$host:8080;
    }
    location @companyPasswd {
      auth_basic "Restricted";
      auth_basic_user_file /etc/nginx/.passwd/company;
      proxy_pass  http://$host:8080;
    }
    \end{verbatim}
    \end{enumerate}

    \item Check the nginx's configuration with {\tt sudo nginx -t}

    \item Reload the nginx's configuration with {\tt sudo nginx -s reload}
\end{enumerate}

\subsection{Management}

\begin{itemize}
    \item Start service:
    \begin{verbatim}[language=Bash]
    {prod} ~/ipolDevel$ sudo nginx
    \end{verbatim}
    \item Reload the configuration file:
    \begin{verbatim}[language=Bash]
    {prod} ~/ipolDevel$ sudo nginx -s reload
    \end{verbatim}
    \item Stop service:
    \begin{verbatim}[language=Bash]
    {prod} ~/ipolDevel$ sudo nginx -s stop
    \end{verbatim}
    \item Check configuration:
    \begin{verbatim}[language=Bash]
    {prod} ~/ipolDevel$ sudo nginx -t
    \end{verbatim}
\end{itemize}


\section{Control Panel}
To operate in a production environment is necessary to install and configure some extra dependencies. In this case, Gunicorn and Nginx are
required for this purpose. The first one will work as the application server, while the second is a reverse proxy.

\begin{itemize}
    \item \textbf{Reverse Proxy} is a type of proxy that retrieves resources on behalf of a client from one or more servers.
    These resources are then returned to the client as if they originated from the proxy server itself. The reverse proxy in this case is
    implemented with NGINX and is used to redirect requests from port 80 to the Control Panel listening port.
    \item \textbf{WSGI} is a specification to connect web servers with web applications or frameworks for the Python programming language.
    In this case the Gunicorn is the responsible of this purpose.
    \item \textbf{Web Application} is a is a client–server software application in which the client runs in a web browser. In the Control Panel this
    is implemented with Django.
\end{itemize}

\subsection{Communication between the Client and Control Panel}
The communication between the client and the Control Panel varies according to the environment in which it is performed.
The differences between them are described below.

The communication between the client and the Control Panel in local is stablished by a reverse proxy. This reverse proxy is implemented with
NGINX and allows the client to do the requests in the 80 port. That request is intercepted by NGINX and send to the 8000
port where Django is running. The other purpose of NGINX is to serve the static content and remove that responsability from Django.
The diagram of this configuration is represented by Figure ~\ref{fig:local_architecture}.

\begin{figure}[!ht]
    \centering
    \includegraphics[width=0.7\columnwidth]{images/local}
    \caption{The communication between the client and the Django web server with the reverse proxy in the local server.}
    \label{fig:local_architecture}
\end{figure}

In the production and integration servers is where is located the most complete connection. As in the local server, a reverse proxy is needed to
make the redirections to hide to the client in wich port is Django running and to provide all the static files. In addition, in the production
and integration servers a WSGI is also needed to receive the http request and send them to Django. This WSGI is implemented with Gunicorn and
communicates with the NGINX through a UNIX socket. The diagram of this configuration is represented by Figure ~\ref{fig:prod_int_architecture}.


\begin{figure}[!ht]
    \centering
    \includegraphics[width=1\columnwidth]{images/prod_int}
    \caption{The communication between the client and the Django web server with the reverse proxy and the WSGI in the production and integration servers.}
    \label{fig:prod_int_architecture}
\end{figure}

\subsection{Gunicorn: configuration}
In order to manage the gunicorn service we will use a script, which is in charge of:
\begin{itemize}
    \item Open the virtual environment, if used. If not, comment out the line with \#.
    \item Collect the static files.
    \item Start the web server.
\end{itemize}

In this guide we will use the following path/name for the mentioned script:
\begin{verbatim}[language=Bash]
ipolDevel/gunicorn_start.sh
\end{verbatim}

Open the script and configure the parameters:
\begin{itemize}
    \item NAME: Name of the application.
    \item DJANGODIR: Django project directory path (absolute).
    \item SOCKFILE: Gunicorn socket path (absolute).
    \item VENV: Virtual environment name (if used).
    \item USER, GROUP: User and group names, to run the server as. Both names must be valid at the current server.
    \item NUM\_WORKERS: Gunicorn worker processes number.
    \item DJANGO\_SETTINGS\_MODULE: Django settings name.
    \item DJANGO\_WSGI\_MODULE: Django WSGI module name.
    \item Gunicorn port number. In this guide we will use port 8001. Consider that this is NOT the port used to access the final site, because it will not serve the static files (DEBUG = False in settings.py). Another port will be configured in Nginx for that purpose.
    \item Finally, add execution permissions to the script.
\end{itemize}

\subsection{Gunicorn: management}
\begin{itemize}
    \item Start service by executing the script:
    \begin{verbatim}[language=Bash]
    {prod} ~/ipolDevel$ ./gunicorn_start.sh
    \end{verbatim}

    \item Stop service: Ctrl + C
\end{itemize}



\subsection{Accessing the Control Panel}
To access the Control Panel the users need to go to \url{http://ipolcore.ipol.im/cp/} and log in with their username and password.

\section{Docker}
A docker image is available to develop and run the IPOL demo system in any enviroment (say, MacOS and others).

\paragraph{Usage}:
The necessary commands in order to work with docker will be described in the next section. The first thing you should do is
build the Docker image, then you will be able to create as many containers as you want. Then run the container and you
will have a terminal inside so you will be able to execute the terminal.py and bring up all modules. Nginx and ssh will be already
configured and running.

Once inside the container tty there will be a user called ``ipol" wich should be used to execute any task related to modules, ipol terminal, 
cp or django. For sysadmin tasks that result in a change in the system imply that a change in the dockerfile is needed.
 
In order to run the Django server for the control panel you will have to make the migrations once per
container before actually running the server. For this purpose there is a script under the Docker folder called migrations\_cp.sh.
 After the migrations run the Django server as you would anywhere else: python manage.py runserver 127.0.0.1:8000 or use the available 
 alias there is for it that will be explained next.
 
 To improve usage of the docker container, some alias have been created to gain easy access to the terminal and to execute the control panel:
 \begin{itemize}
 	\item terminal: cd into the terminal directory and execute terminal.py
 	\item cpanel: Launches the control panel at 127.0.0.1 on port 8000.
 	\item cp2: Launches control panel 2 at 127.0.0.1 on port 8000.
 	\item collectstatic: collects all the static files for the control panel.
 	\item runtest: runs all the tests for each module.
 	\item module\_name: There is an alias for every module to excecute them separatelly. e.g. blobs.
 	\item rund: change directory to the run folder
 \end{itemize}


\paragraph{Docker build}:\\

Run this command inside the ipolDevel repository you previously cloned.

\begin{verbatim}[firstnumber=1,breaklines]
  $ docker build . -t ipol -f ./docker/Dockerfile
\end{verbatim}

With this command we will have docker create an image from the Dockerfile in the root of the project. It will go through the creation and configuration of the development envirorment. This command has to be executed from inside the project root folder. Explanation:
\begin{itemize}
  \item docker build: command to build an image
  \item {\tt .}: The context of the image. Here, the current folder is ipolDevel's repository root.
  \item -t ipol: Tag the image with the name ipol to reference it later.
  \item -f: flag to specify a Dockerfile
  \item {\tt ./docker/Dockerfile}: Location of the Dockerfile defining the image. Given that we are located in ipolDevel's repository root.
\end{itemize}

\paragraph{Docker run}:\\
\begin{verbatim}[firstnumber=1,breaklines]
  $ cp ipol_demo/modules/config_common/authorized_patterns.conf.sample ipol_demo/modules/config_common/authorized_patterns.conf
  $ docker run -it -v $(pwd):/home/ipol/ipolDevel -p 80:80 -h docker --add-host docker:127.0.0.1 --name ipol ipol
\end{verbatim}

This command will create a container and log us in the terminal. Explanation:
\begin{itemize}
  \item docker run: command to create a container
  \item -it: makes the container interactive and attaches to a tty or terminal.
  \item ipolDevel volume (-v): first -v parameter creates a volume to share the project folder between the container and the host machine.
  As docker run does not accept relative paths, we use \$(pwd) to get back the currect directory: ipolDevel's repository root as always. If you are on
  Windows, you can use \%cd\% to get back the current path. 
  \item authorized\_patterns.conf volume (-v): this second -v parameter adds a volume which essentially creates the authorized\_patterns.conf file at the 
  needed location on container creation. 
  This will overwrite the default values but since this container is for development purposes only there is no need to modify the default values.
  \item -p 80:80: exposes port 80 in the container and links it to port 80 in the host machine.
  \item -h docker: defines the container's hostname
  \item --add-host docker:127.0.0.1: adds an entry to /etc/hosts mapping 127.0.0.1 to the host
  \item -name ipol: assigns the name ipol to the container for future reference
  \item ipol: tells docker to run a container from the image "ipol"
\end{itemize}

After this command we will be inside the containers tty. This command should be used each time after a docker build is done,
otherwise if the container is already exists, it will have to be removed or attached to. The orders to control containers and images are:

\paragraph{Docker start}:\\
In order to start the already created container.
\begin{verbatim}[firstnumber=1,breaklines]
  $ docker start -i ipol
\end{verbatim}

\paragraph{Docker exec}:\\
In order to attach a new terminal to the container. Useful if you need more than one terminal access to the container.
\begin{verbatim}[firstnumber=1,breaklines]
  $ docker exec -it ipol bash
\end{verbatim}

\paragraph{Docker ps}:\\
In order to get information about all the created containers.
\begin{verbatim}[firstnumber=1,breaklines]
  $ docker ps -a
\end{verbatim}

\paragraph{Docker images}:\\
In order to get information about all the created images.
\begin{verbatim}[firstnumber=1,breaklines]
  $ docker images
\end{verbatim}

\paragraph{Docker rm}:\\
In order to remove a container. The id or name provided will be available doing "docker ps -a"
\begin{verbatim}[firstnumber=1,breaklines]
  $ docker rm 'docker_image_id'
\end{verbatim}

\paragraph{Docker rmi}:\\
In order to remove an image. The id or name provided will be available doing "docker images"
\begin{verbatim}[firstnumber=1,breaklines]
  $ docker rmi 'docker_image_id'
\end{verbatim}

\paragraph{Once you are on the container's terminal}:\\

Which means you executed the \textbf{docker run} or the \textbf{docker start} command above.

Switch to the ipol user:
\begin{verbatim}[firstnumber=1,breaklines]
  $ su ipol
\end{verbatim}

Open IPOL's terminal:
\begin{verbatim}[firstnumber=1,breaklines]
  $ terminal
\end{verbatim}

You should be in a new terminal now, like this one:
\begin{verbatim}[firstnumber=1,breaklines]
  IPOL>
\end{verbatim}

Switch all modules to local
\begin{verbatim}[firstnumber=1,breaklines]
  IPOL> env local0
\end{verbatim}

Start all modules
\begin{verbatim}[firstnumber=1,breaklines]
  IPOL> startall
\end{verbatim}
If the process is stuck when starting a module, press ctrl+c and it should continue.

When you ping them all, they should be marked "OK"
\begin{verbatim}[firstnumber=1,breaklines]
  IPOL> pingall
\end{verbatim}
If core and demoinfo are still unresponsive, create empty files /home/ipol/ipolDevel/ipol\_demo/modules/core/local.conf and /home/ipol/ipolDevel/ipol\_demo/modules/demoinfo/local.conf.

You can now leave the terminal, cd to ipol\_webapp, create its venv, activate it, install its 
requirements and make its migrations.
\begin{verbatim}[firstnumber=1,breaklines]
  IPOL> exit
  $ cd ~/ipolDevel/ipol_webapp/
  $ python3 -m virtualenv -p /usr/bin/python2.7 venv
  $ source venv/bin/activate
  (venv) $ pip install -r requirements.txt
  (venv) $ ~/ipolDevel/docker/migrations_cp.sh
\end{verbatim}

Note: An error about a missing distribution for Django might be displayed, but you can safely ignore it.

The next step is to create a super user for cpanel. Still with the \emph{venv} we just created, and
still in \emph{\~/ipolDevel/ipol\_webapp}:
\begin{verbatim}[firstnumber=1,breaklines]
  (venv) $ python manage.py createsuperuser
\end{verbatim}

Choose a username, email address, and a password of your choice.

\textbf{Important}: the only thing left to do is to download the staticData and db folders for the demoInfo
and blobs modules. 
Then extract the content of these folders respectively in \emph{$./ipol\_demo/modules/blobs$}
and in \emph{$./ipol\_demo/modules/demoInfo$} so that both of them have a staticData and db folders
with the new files. Paths are relative to ipolDevel's repository root.

You can now run cpanel with:
\begin{verbatim}[firstnumber=1,breaklines]
  $ cpanel
\end{verbatim}
And access it at \emph{http://127.0.0.1/cp/login/}. Use the credentials of the super user you created
above. If you are in docker you can use the {\tt cpanel} command to start it, for development. Note that in production the Control Panel is started with the script {\tt gunicorn\_start.sh}.

The list of demos appear locally \emph{http://<server>/demo/}. Change {\tt <server>} to {\tt 127.0.0.1} if running locally, or change by the address of the server on the Internet.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Backups}
\label{sec:backups}
The backups are done by this script: {\tt ipolDevel/sysadmin/backup.sh}
We execute the backup script as root (use {\tt sudo crontab -e}) to avoid eventual read permission problems.

This script creates incremental backups and copies them to other servers, allowing to recover the data in the system in case of a fatal disk failure (say, the database of the Archive or others). An incremental backup is a kind of backup that will only add changes which are new with respect to the last backup. This results backups of a smaller size as well as faster archiving.

Every quarter of the year all the stored data, including temporary files are backuped. This is known as a \emph{level-0} backup. Every week and until the next quarter (when a new full level-0 backup will start) it is performed  a different backup with only the incremental changes with respect to the last week. It is known as a \emph{level-1} backup

We use the following line to run the backup script once per week at 3:00h:

{\tt 0 3 * * 1 /home/ipol/ipolDevel/sysadmin/backup.sh}

We have identified problems with the extraction of incremental {\tt tar} backups in the same folder. When using {\tt tar} some files will give file substitution errors. This most probably this happens because of an undocumented bug in the {\tt tar} command. In order to minimize extraction errors, the only way we have found which results in no errors consists in extracting every needed backup in a different folder and then mixing every folder with the first backup of the semester with the {\tt rsync} command. This last step must be done in order of backup creation. Mixing files with rsync has also its own caveats: after mixing the extracted files we occasionally end up with more files than originally in the backup. Some removed files that actually were removed at some incremental copy anyway exist in mixed backup and will not be removed. However, this is not especially dangerous as we end up with more files than needed. This might happen because of a file permission problem or a bug in the {\tt rsync} command.

The backups are organized by yearly semesters folders:

{\tt /home/ipol/backups/<YEAR>-<SEMESTER>/backup\_<DATE>.tar.gz}

For every semester there will be one backup file or every week according to the configuration of the cronjob. There will also be a snapshot file that is used by the tar command to keep a log of the files that have changed from one backup to another. This way it can backup files that change between one backup and the next. This snapshot is only used during the backup process, it will not be of any use during extraction but in case of corruption or if it is removed. In that case, tar would not find it and would therefore create a level-0 backup. 

When restoring an incremental backup the destination path needs to be specified as a parameter or otherwise it will overwrite the original path for the backed up files. For example:

{\tt tar xvfz backup\_file.tgz -g /dev/null --ignore-zeros -C restore\_folder}

The procedure for extraction we apply is the following:

\begin{enumerate}
  \item Locate the semester folder needed to restore For example: 2020-2.
  \item For a given date, extract every backup in the semester until the needed date to be restored. As previously stated, extract each backup on a separate folder. For each backup adapt the following example:

  {\tt tar xvfz backup\_file\_<DATE>.tgz -g /dev/null --ignore-zeros -C restore\_folder\_<DATE>}
  \item Once we have all the needed backups extracted, we will merge extracted folders against the first backup of the semester which is the level-0 backup containing a full backup. This has to be done in order of date, from older to newer. For example:
  
  {\tt rsync -av restore\_folder\_<DATE>/ restore\_folder\_<DATE\_OF\_THE\_FIRST\_BACKUP>/ 2>> errors.log}

  As we can see in the example we first put the source of the rsync (data to be copied to another folder) and then the folder of the level 0 backup. Note that trailing slashes are importante when using rsync command.
  \item When all backups are merged with the level 0 backup we will have a complete snapshot of the ipolDevel folder for a given date.
\end{enumerate}

While making backups is a good way to be able to recover in case of data loss, it is even better to copy redundant files to other servers. Just as data can be corrupt or lost, servers have downtime and there is always the possibility of a server malfunction. Thus, in order to improve backups reliability we synchronize our backup folder with another server just in case of rare catastrophic event. Along with the backups script there is a script called backup\_sync.sh that automatically synchronizes with rsync the backup folder from one server to another thus making our backups redundant.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Unattended Upgrades}

The system is automatically updated based on the latest stable version. To achieve this the IPOL servers use the UnattendedUpgrades package that allows a machine to download and upgrade the system according to the "Origins-Pattern" list without updating any package in the "Blacklist". These are useful commands to manage this package: 

Edit the configuration: 
\begin{verbatim}[firstnumber=1,breaklines]
  $ editor /etc/apt/apt.conf.d/50unattended-upgrades
\end{verbatim}

Edit the downloads schedule: 
\begin{verbatim}[firstnumber=1,breaklines]
  $ sudo systemctl edit apt-daily.timer
  $ sudo systemctl restart apt-daily.timer
  $ sudo systemctl status apt-daily.timer
\end{verbatim}

Edit the upgrade schedule: 
\begin{verbatim}[firstnumber=1,breaklines]
  $ sudo systemctl edit apt-daily-upgrade.timer
  $ sudo systemctl restart apt-daily-upgrade.timer
  $ sudo systemctl status apt-daily-upgrade.timer
\end{verbatim}

Check the next execution: 
\begin{verbatim}[firstnumber=1,breaklines]
  $ systemctl list-timers
\end{verbatim}

View the installed packages: 
\begin{verbatim}[firstnumber=1,breaklines]
  $ cat /var/log/apt/history.log
\end{verbatim}

Manually execute unattended upgrade:
\begin{verbatim}[firstnumber=1,breaklines]
  $ sudo unattended-upgrade -d
\end{verbatim}

Some package updates require user input to decide wether to keep or renew the possible modified config files. In order to keep our older modified configurations for a package we use the following option in the unattended upgrades configuration:

\begin{verbatim}[firstnumber=1,breaklines]
  Dpkg::Options {
    "--force-confdef";
    "--force-confold";
  };
\end{verbatim}


\section{Troubleshooting}

\textbf{After a new release of Debian Stable the binaries of the demos no longer work}

Probably it is because the binaries where staticly compiled againts libraries whose versions are no longer installed in our servers. Remove the directory {\tt ipolDevel/ipol\_demo/modules/demorunner/binaries} of all the machines where a demoRunner module has been installed.
\vspace{0.5cm}

\textbf{It installed a package but it does not seem to be installed}

It is possible that you installed a Python 3 package and you are looking for the Python 2 version, or the opposite. Pay attention to use the right package according to the Python version when installing with {\tt apt}. With {\tt pip} write explicitly {\tt pip2} or {\tt pip3} when installing.
\vspace{0.5cm}


\textbf{Python fails to import libtiff}

It needs to generate a header in a directory at which only root can write. Thus, execute ipython as root and then execute {\tt import libtiff}. After this, non-privileged users will be able to import the library normally.
\vspace{0.5cm}

\textbf{After uploading a package Python complains about not being able to import a package because a system library is not at the correct version, even if I uninstall/install the package with {\tt pip}.}

Normally the reason is that pip is not managing the cache correctly and it is installing an old version of the package which needs an old version of the system library. Remove the pip cache: {\tt rm -rf /root/.cache/pip}.
\vspace{0.5cm}

\textbf{Even though, some packages can not be installed.}

It might happen that one of the packages to be installed needs a version behind the last version of package that is also going to be installed. For example, we found that with netcdf and numpy. In that case, unfortunately the best is not to install the last version of numpy or the affected package and let the other install a not-so-updated dependency.

It also can happen that you do not manage to install the last version of the packages because of the cache. In that case, remove both the cache and the installed files on disk. For example:

\begin{verbatim}
pip2 uninstall netcdf numpy tensorflow opencv-python

rm /root/.cache/pip -rf

rm -rf /usr/local/lib/python2.7/dist-packages/opencv_python*
rm -rf /usr/local/lib/python2.7/dist-packages/numpy*
rm -rf usr/local/lib/python2.7/dist-packages/tensorflow*
rm -rf usr/local/lib/python2.7/dist-packages/netcdf*

pip2 install numpy tensorflow opencv-python netcdf
\end{verbatim}
\vspace{0.5cm}

\textbf{VirtualBox does not work.}

Check that you have installed the needed VirtualBox packages, specially the kernel module (virtualbox-guest-dkms).
If you have everything installed and it is still not working, then execute {\tt dpkg-reconfigure virtualbox-guest-dkms} to force the re-compilation of the kernel module.

If still does not work, then purge the packages and re-install:

\begin{verbatim}
apt purge virtualbox-dkms virtualbox-guest-dkms
apt install linux-headers-amd64 virtualbox-5.1
\end{verbatim}
\vspace{0.5cm}

\textbf{When I try to run a Python script I get the following error message: \emph{[Errno 8] Exec format error - errno=8}.}

Probably you are editing the Python script in windows and it finished the line with {\tt CR LR} instead of just {\tt LF}, as used in Linux systems. This causes the shebang line to have an incorrect name for the interpreter: {\tt \#!/usr/bin/env python3<CR>}. To fix it, configure your editor you use {\tt LF} ({\tt \textbackslash n}) when saving the file.
\vspace{0.5cm}

\textbf{A docker container will not run after a daemon fails to start}

The main reason is a broken configuration file of a daemon. To fix this copy a correct version of the configuration file that prevents the container to start. You can use the {\tt docker cp} command to do it:

\begin{verbatim}
docker cp correct_config ipol:/path_to_broken_config
\end{verbatim}

\textbf{When updating nginx with apt I get the following error: systemd[1]: nginx.service: Control process exited. dpkg: error processing package nginx-full (--configure):  subprocess installed post-installation script returned error exit status 1 Errors were encountered while processing:  nginx-full}

It happens sometimes is a previous version of nginx is running and the system can't stop it before installing over the new one. Try {\tt sudo nginx -s stop} or it this fails directly kill the process with {\tt sudo killall nginx}.
\vspace{0.5cm}

\textbf{I can only access the server's pages or API services using the IP in the URL, but not its domain server. I have also messages in {\tt /var/log/nginx/error.log} about not being able to resolve localhost...}

...such as these ones:
\begin{verbatim}
2021/08/15 22:53:49 [error] 1410#1410: send() failed (111: Connection refused) while resolving, resolver: 127.0.0.1:53
2021/08/15 22:53:49 [error] 1410#1410: send() failed (111: Connection refused) while resolving, resolver: 127.0.0.1:53
2021/08/15 22:53:54 [error] 1410#1410: *37 localhost could not be resolved (110: Operation timed out), client: ::1, server: ipolcore.ipol.im, request: "GET /api/core/ping HTTP/1.1", host: "localhost"
\end{verbatim}



Nginx checks if the FQDN specified in the URL corresponds to the current server. To do it, it needs to make a request to a DNS server (localhost by default, or specified as {\tt resolver <IP address>;}. The bind9 DNS server needs to be installed in the machine (no configuration change is needed, it should work out of the box).
\vspace{0.5cm}

\textbf{Modules and tests fail to execute}

The following message is shown when starting a module or a test:

\begin{verbatim}  
  Could not find platform independent libraries <prefix>
  Could not find platform dependent libraries <exec_prefix>
  Consider setting $PYTHONHOME to <prefix>[:<exec_prefix>]
  Fatal Python error: Py_Initialize: Unable to get the locale encoding
  ImportError: No module named 'encodings'
\end{verbatim}

The reason is likely to be an incompatibility with a recently updated Python version or other distribution packages. To solve it simply remove and recreate the corresponding virtual environments.

\textbf{DemoExtras executing ffmpeg blocks access to file when redirecting output}

When redirecting all standard output of the {\tt ffmpeg} command, the resulting file might stay blocked for a short period of time where the Python script that run the {\tt ffmpeg} command might continue its execution. This might be a problem as the file continues blocked but the execution of the script continues and might need access to the file.

Example of the problem:

{\tt ffmpeg -i file.mp3 \&> output.txt}

Everything seems to work fine when only redirecting errors to a file instead of everything:

{\tt ffmpeg -i file.mp3 2> output.txt}

\textbf{GDAL fails to install with pip}

Check with {\tt gdal-config --version} the version installed in the server and then specify that version in the requirements.txt.

\textbf{Bash script virtualenv activation fails while using set -u}

When a demo has a virtualenv in order to execute Python code it needs to activate said virtualenv from a bash script inside DemoExtras. If the bash script uses set -u it will fail when activating virtualenv because of a bug in the activation script throwing 'PS1: unbound variable'. This bug has been known for years and the solution still hasn't reached production versions of the package in some linux distributions. To fix this we can simply define the following variable as a patch while the official virtualenv fix reaches production:

{\tt VIRTUAL\_ENV\_DISABLE\_PROMPT=true}

\textbf{Virtualenv is created with old pip version}

Every GNU/Linux distribution manages packages shipped differently, a new release will most probably come with a version of Python which is not the latest. Since the virtualenv package is independent from the Python language release cycle most probably the version of pip installed within a virtualenv is outdated. This will cause a warning on every installation within a virtualenv, just because the Python version comes by default with an outdated pip version. Even if the system has an up-to-date version of pip, virtualenvs will still be created with a different (outdated) one.

\textbf{A commit was made directly to the master branch by mistake and now the merge is not automatic}

Execute the following in the devel branch to re-synchronize the two branches: {\tt git rebase master}

\textbf{The command {\tt apt dist-upgrade} cannot be executed because not enough free space on disk is available. It fails with the message \emph{E: You don't have enough free space in /var/cache/apt/archives/.}}

To avoid resizing the root partition, a simply solution is to move {\tt /var/cache/apt/} to the home directory.
Create a new folder {\tt /home/system/} and copy {\tt /var/cache/apt/} inside. Then remove {\tt /var/cache/apt/} and create a symlink {\tt /var/cache/apt/ -> /home/system/apt/}
Do never to the same with directories containing libraries!

\textbf{DR (or any other modules) fails to install its own venv with a message similar to \emph{ERROR: Could not build wheels for scipy which use PEP 517 and cannot be installed directly}.}

Most probably the {\tt setuptools} and {\tt wheel} packages are not installed or outdates. They are needed to create virtual environments, and therefore they need to be installed or updated before. Install them with

{\tt pip3 install --user --upgrade pip setuptools wheel}.



\bibliographystyle{plain}
\bibliography{biblio}

\end{document}
% End of document
