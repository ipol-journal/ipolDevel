% Instructions to modify this document:
% * Remember to ALWAYS execute "git pull" BEFORE any commit you make!
% * Use the \ToDo{...} command to remark tasks which still need to be done. Add your name in the comment.
% * Use the \input{file.tex} command to split the document into several parts
% * Do not change the current LaTeX coding style to yours. The style and format should be homogeneous along sections.

% To convert .dia diagrams into PDF:
% 1) Create the diagram with dia
% 2) Export it as .eps
% 3) use epstopdf to convert to PDF
%
% Editing SVG files and exporting them to PDF with Inkscape is admitted too.
% Remember to keep a copy of the editable file (.dia or .svg files).


\documentclass[a4paper,12pt]{article}

\usepackage[utf8]{inputenc}
\usepackage{amsmath,graphicx}
\usepackage{bm}
\usepackage{amssymb}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{subfigure}
\usepackage{ifpdf}
\usepackage{url}
\usepackage{color}
\usepackage[hidelinks]{hyperref}
\usepackage{multirow}
\usepackage{datetime}
\usepackage{comment}
\usepackage{float} % To put figures in their exact place with \begin{figure}[H]
\usepackage{longtable}
\usepackage{tabularx}
\usepackage{listings}
\usepackage{xcolor}


% Definitions and commands
\def \np{\vskip 0.25 cm}
\def \ap{\vskip 0.15 cm}

\lstset{language=Bash, basicstyle=\color{gray}}

\newcommand{\ToDo}[1]{\textcolor{magenta}{\textbf{[ToDo]} \textbf{#1}}}
\newcommand{\miguel}[1]{\textcolor{magenta}{\textbf{[Miguel]} \textbf{#1}}}


\begin{document}

\begin{titlepage}

\begin{center}
\vspace*{-1in}

\vspace*{0.6in}
\begin{Large}
\textbf{The IPOL Demo System 2.0 \\System Administration Documentation} \\
\end{Large}

\vspace*{0.6in}

\small{Compiled on \today\ at \currenttime}

\vspace*{0.6in}
\rule{80mm}{0.1mm}\\
\vspace*{0.1in}
\end{center}

\end{titlepage}

This document contains System Administration documentation for the IPOL Demo System 2.0.
\vspace*{0.6in}


%\maketitle
\newpage

\tableofcontents
\newpage
% \listoffigures
% \newpage

\section{Get the source}
Use git to get the IPOL sources. The ipolDevel folder MUST be in your home directory.
\begin{verbatim}
~$ cd
~$ git clone https://github.com/mcolom/ipolDevel.git
~$ cd ipolDevel/
~/ipolDevel$
\end{verbatim}

The production servers use the {\tt master} branch, but for development the {\tt devel} branch MUST be used, never master.
\begin{verbatim}
git checkout devel
\end{verbatim}

\section{Requirements: Debian and Python}
A minimal requirement for IPOL is Debian Stable.
Tools are provided to ease installation of dependencies in ~/ipolDevel/sysadmin/install\_packages/
\begin{verbatim}
~/ipolDevel$ cd sysadmin/install_packages/
\end{verbatim}

Install the Debian package list, apt-get\_requirements.txt:
\begin{verbatim}
~/ipolDevel/sysadmin/install_packages$ sudo ./install_dist_packages.sh
\end{verbatim}

Install the Python packages list with pip, requirements.txt:
\begin{verbatim}
pip install -r requirements.txt
\end{verbatim}


\section{Crontab scripts}
The system needs to periodically execute administration script, to create backups, clean up old data, or to perform continuous integration tests. This section describes these scripts.

To modify the crontab configuration, the command is {\tt crontab -e}. The format of the crontab lines is: minute (m), hour (h), day of month (dom), month (mon), and day of week (dow), or use '*' in these fields (for 'any').

\begin{itemize}
    \item \textbf{Backups}: they are done by this script: {\tt ipolDevel/sysadmin/backup.sh}
Since we do not want to the backup is not done just because some files can not be read because of their permission, we execute the backup script as the root user (use {\tt sudo crontab -e}).

We use the following line to run the backup script once per week at 3:00h:

    {\tt 0 3 * * 1 /home/ipol/ipolDevel/sysadmin/backup.sh}

    \item \textbf{Cleanup}: the script {\tt ipolDevel/sysadmin/cleanup.sh} does a cleanup of all temporary files older than one month.

    {\tt 0 5 * * 1 /home/ipol/ipolDevel/sysadmin/cleanup.sh}

    \item \textbf{PyLint report}: the script {\tt ipolDevel/ci\_tests/pylint.sh} uses PyLint to create code quality reports. It executes weekly in the integration server and sends an email to the addresses in the file {\tt send\_to.txt}

    {\tt 0 15 * * 2 /home/ipol/ipolDevel/ci\_tests/pylint.sh}

    \item \textbf{pdflatex report}: the script {\tt ipolDevel/ci\_tests/pdflatex.sh} checks if the Latex documentation of the project compiles and sends and email otherwise.

    {\tt 0 15 * * 2 sudo -u ipol /home/ipol/ipolDevel/ci\_tests/pdflatex.sh}

    \item \textbf{Reboot}: the script {\tt ipolDevel/sysadmin/on\_reboot.sh} starts all IPOL modules, nginx and the shared folder in the production machines, and sends a warning email. To execute it, the following line needs to be added with {\tt crontab -e} as root.

    {\tt @reboot ipolDevel/sysadmin/on\_reboot.sh}
\end{itemize}

\section{GitHub deploy key}
The IPOL GitHub repository might be private. Thus, is any server needs to obtain the complete source code of the demo system, a \emph{deploy key} is needed. The deploy key is added to the GitHub configuration and each server needs to get the sources using the deploy key.

For example:

\begin{verbatim}
ipol@smartalgo:~/ipolDevel$ cat ~/.ssh/config
host github_deploy
      hostname github.com
      user git
      identityfile ~/.ssh/id_rsa_deploy
\end{verbatim}

\vspace{0.15cm}

\begin{verbatim}
ipol@smartalgo:~/ipolDevel$ cat .git/config
[core]
	repositoryformatversion = 0
	filemode = true
	bare = false
	logallrefupdates = true
[remote "origin"]
	#url = https://github.com/mcolom/ipolDevel
	url = git@github_deploy:mcolom/ipolDevel.git
	fetch = +refs/heads/*:refs/remotes/origin/*
[branch "master"]
	remote = origin
	merge = refs/heads/master
\end{verbatim}

We use the host \emph{github\_deploy} in order to pick the deploy key in the SSH connection.

\section{Setup of a new machine}
When a new machine is added to the IPOL infrastructure, the following needs to be done:
- Create the {\tt ipol} user in a new machine: {\tt adduser --disabled-password ipol}

- Install bash-completion {\tt apt-get install bash-completion}

- Configure the SSH server to allow only access with public key and not with password. Set the following in /etc/ssh/sshd\_config:
{\tt PasswordAuthentication no}

{\tt RSAAuthentication yes}

{\tt PubkeyAuthentication yes}

And restart the SSH server with {\tt service ssh restart}

- Install cron-apt: {\tt apt-get install cron-apt}

And edit /etc/cron-apt/config:
\begin{verbatim}
APTCOMMAND=/usr/bin/apt-get
OPTIONS="-o quiet=1 -o Dir::Etc::SourceList=/etc/sources.list"
SYSLOGON="always"
\end{verbatim}

- Configuration of the email server to be able to send emails form any of the IPOL servers: configure with {\tt dpkg-reconfigure exim4-config} and be sure to choose the option to send email on the Internet, not local.

Install mail with {\tt apt-get install mailutils}

It is important to set the hostname with the real Internet address in {\tt /etc/hosts} to send the emails outside. For example, for the ipolcore machine, the configuration is the following:

\begin{verbatim}
5.196.85.84             ipolcore.ipol.im     ipolcore
2001:41d0:a:7654::1     ipolcore.ipol.im     ipolcore
\end{verbatim}

Example of sending an email: {\tt cat email.txt | mail -s "This is the subject" john.doe@example.com,banania.guy@example.com}


\begin{comment}
- Setup priorities and memory limits to the processes of the users.

Added this to /etc/security/limits.conf:
\begin{verbatim}
*               soft     priority            17
ipol            soft     priority            0
\end{verbatim}

We need to set also limits for the memory usage per user. It'd be great if we could do it as a percentage of the free memory.

git@github_deploy:mcolom/ipolDevel.git
To limit the memory which a group of users can use, we should use {\tt cgroups} along with the {\tt Cgred} daemon.

More info:

\url{https://www.digitalocean.com/community/tutorials/how-to-limit-resources-using-cgroups-on-centos-6}

\url{https://access.redhat.com/documentation/en-US/Red_Hat_Enterprise_Linux/6/html/Resource_Management_Guide/sec-Moving_a_Process_to_a_Control_Group.html}
\end{comment}

To clone the ipolDevel repository in a new machine, the SSH access must be configured with the RSA deploy key so ssh can use it to clone the repository. This allows to clone the repository even if it eventually becomes private.
%
The deploy private key must be copied to {\tt .ssh/id\_rsa\_deploy} and the following lines need to be added to .ssh/config:

\begin{verbatim}
host github_deploy
      hostname github.com
      user git
      identityfile ~/.ssh/id_rsa_deploy
\end{verbatim}

Then, clone the repository with {\tt git clone git@github\_deploy:mcolom/ipolDevel.git}

\section{Nginx}

\subsection{Installation}

\begin{enumerate}
\item Debian

\begin{enumerate}
    \item Uninstall previous nginx version
    \begin{lstlisting}[language=Bash]
	{prod} ~/ipolDevel$ apt-get remove nginx-common
    \end{lstlisting}

    \item Download the key from: \url{http://nginx.org/keys/nginx_signing.key} and execute the following command with it
    \begin{lstlisting}[language=Bash]
	{prod} ~/ipolDevel$ sudo apt-key add nginx_signing.key
    \end{lstlisting}

    \item Replace codename with Debian distribution codename, and append the following to the end of the /etc/apt/sources.list file:
    \begin{enumerate}
	\item deb http://nginx.org/packages/debian/ codename nginx
	\item deb-src http://nginx.org/packages/debian/ codename nginx
    \end{enumerate}

    \item Update repositories
    \begin{lstlisting}[language=Bash]
    {prod} ~/ipolDevel$ apt-get update
    \end{lstlisting}

    \item Install nginx from the repository
    \begin{lstlisting}[language=Bash]
    {prod} ~/ipolDevel$ apt-get install nginx
    \end{lstlisting}
    \end{enumerate}
    
    \item Ubuntu
    \begin{enumerate}
	\item Install nginx from the repository
	\begin{lstlisting}[language=Bash]
	{prod} ~/ipolDevel$ apt-get install nginx
	\end{lstlisting}
    \end{enumerate}    
\end{enumerate}

\subsection{Configuration}

To configure the reverse proxy, we will use the sites-enabled, sites-available directories structure, which are located at:
\begin{lstlisting}[language=Bash]
/etc/nginx/sites-available
/etc/nginx/sites-enabled
\end{lstlisting}

\begin{enumerate}
    \item Edit the config file /etc/nginx/nginx.conf, adding the following include at the end of the http subsection:
    \begin{lstlisting}[language=Bash]
    include /etc/nginx/sites-enabled/*;
    \end{lstlisting}
    \item Edit the site configuration file: sites-available/default, configuring the subsections:
    \begin{enumerate}
    \item Upstream
    \begin{enumerate}
    \item Upstream name. E.g.: ipol\_webapp\_server
    \item Gunicorn socket file absolute location.
    \end{enumerate}
    \item Server
    \begin{enumerate}
    \item Listening port. The port to serve the site with static files. E.g.: 8000
    \item Server name. E.g.: ipolcore.ipol.im
    \item A resolver, necessary to set variables in the configuration for Debian distributions.
    \begin{lstlisting}[language=Bash]
    resolver 213.186.33.99;
    \end{lstlisting}
    \item Increase timeout for send and receive requests.
    \begin{lstlisting}[language=Bash]
    proxy_send_timeout	600;
    proxy_read_timeout	600;
    send_timeout		600;
    \end{lstlisting}
    \item Access log absolute location.
    \item A location for each module.
    \begin{lstlisting}[language=Bash]
    location /api/<module>/ {
      rewrite ^/api/<module>/(.*) /$1 break;
      proxy_pass  http://$host:<port>;
    }
    \end{lstlisting}
    \item Static files absolute location.
    \begin{lstlisting}[language=Bash]
    location /cp/static/ {
      alias  /home/<user>/IPOLWEBAPP_STATIC/;
    }
    \end{lstlisting}
    \item Proxy pass, using upstream name configured previously.
    E.g.:
    \begin{lstlisting}[language=Bash]
    proxy_pass http://ipol_webapp_server;
    \end{lstlisting}

    \end{enumerate}
    \end{enumerate}
    \item Add authentication for demos. Only in the machine which serves the static files of the demo, of course.
    \begin{enumerate}
    \item Create subfolder .passwd in /etc/nginx
    \begin{lstlisting}[language=Bash]
    mkdir /etc/nginx/.passwd
    \end{lstlisting}
    \item Install apache2-utils
    \begin{lstlisting}[language=Bash]
    sudo apt-get install apache2-utils
    \end{lstlisting}
    \item Create username and password with htpasswd
    \begin{lstlisting}[language=Bash]
     sudo htpasswd -c /etc/nginx/.passwd/company company
    \end{lstlisting}
    \item Edit the {\tt default} file to add authentication, e.g. add authentication to all the demos which its id starts with 33333999
    \begin{lstlisting}[language=Bash]
    location /demo/clientApp/demo.html {
      if ($args ~ ".*id=33333999\d*") {
	error_page 418 = @companyPasswd;
	return 418;
      }
      proxy_pass  http://$host:8080;
    }
    location @companyPasswd {
      auth_basic "Restricted";
      auth_basic_user_file /etc/nginx/.passwd/company;
      proxy_pass  http://$host:8080;
    }
    \end{lstlisting}
    \end{enumerate}

	\item Enable gzip compression for static files
	\begin{lstlisting}[language=Bash]
	gzip on;
	gzip_disable "msie6";

	gzip_vary on;
	gzip_proxied any;
	gzip_comp_level 6;
	gzip_buffers 16 8k;
	gzip_http_version 1.1;
	gzip_min_length 256;
	gzip_types text/plain text/css application/json \
	     application/javascript text/xml application/xml \ 
	     application/xml+rss text/javascript;
    \end{lstlisting}
    \item Enable the site by creating a symbolic link to default configuration:
    \begin{lstlisting}[language=Bash]
    ln -s /etc/nginx/sites-available/default \
    /etc/nginx/sites-enabled/
    \end{lstlisting}

    \item Check Nginx configuration
    \begin{lstlisting}[language=Bash]

    \end{lstlisting}
\end{enumerate}

\subsection{Management}

\begin{itemize}
    \item Start service:
    \begin{lstlisting}[language=Bash]
    {prod} ~/ipolDevel$ sudo nginx
    \end{lstlisting}
    \item Reload the configuration file:
    \begin{lstlisting}[language=Bash]
    {prod} ~/ipolDevel$ sudo nginx -s reload
    \end{lstlisting}
    \item Stop service:
    \begin{lstlisting}[language=Bash]
    {prod} ~/ipolDevel$ sudo nginx -s stop
    \end{lstlisting}
    \item Check configuration:
    \begin{lstlisting}[language=Bash]
    {prod} ~/ipolDevel$ sudo nginx -t
    \end{lstlisting}
\end{itemize}


\section{Control Panel}
To operate in a production environment is necessary to install and configure some extra dependencies. In this case, Gunicorn and Nginx are
required for this purpose. The first one will work as the application server, while the second is a reverse proxy.

\begin{itemize}
    \item \textbf{Reverse Proxy} is a type of proxy that retrieves resources on behalf of a client from one or more servers.
    These resources are then returned to the client as if they originated from the proxy server itself. The reverse proxy in this case is
    implemented with NGINX and is used to redirect requests from port 80 to the Control Panel listening port.
    \item \textbf{WSGI} is a specification to connect web servers with web applications or frameworks for the Python programming language.
    In this case the Gunicorn is the responsible of this purpose.
    \item \textbf{Web Application} is a is a clientâ€“server software application in which the client runs in a web browser. In the Control Panel this
    is implemented with Django.
\end{itemize}

\subsection{Communication between the Client and Control Panel}
The communication between the client and the Control Panel varies according to the environment in which it is performed.
The differences between them are described below.

The communication between the client and the Control Panel in local is stablished by a reverse proxy. This reverse proxy is implemented with
NGINX and allows the client to do the requests in the 80 port. That request is intercepted by NGINX and send to the 8000
port where Django is running. The other purpose of NGINX is to serve the static content and remove that responsability from Django.
The diagram of this configuration is represented by Figure ~\ref{fig:local_architecture}.

\begin{figure}[!ht]
    \centering
    \includegraphics[width=0.7\columnwidth]{images/local}
    \caption{The communication between the client and the Django web server with the reverse proxy in the local server.}
    \label{fig:local_architecture}
\end{figure}

In the production and integration servers is where is located the most complete connection. As in the local server, a reverse proxy is needed to
make the redirections to hide to the client in wich port is Django running and to provide all the static files. In addition, in the production
and integration servers a WSGI is also needed to receive the http request and send them to Django. This WSGI is implemented with Gunicorn and
communicates with the NGINX through a UNIX socket. The diagram of this configuration is represented by Figure ~\ref{fig:prod_int_architecture}.


\begin{figure}[!ht]
    \centering
    \includegraphics[width=1\columnwidth]{images/prod_int}
    \caption{The communication between the client and the Django web server with the reverse proxy and the WSGI in the production and integration servers.}
    \label{fig:prod_int_architecture}
\end{figure}


\subsection{Gunicorn: installation}

Install from console:
\begin{lstlisting}[language=Bash]
{prod} ~/ipolDevel$ pip install gunicorn
\end{lstlisting}

\subsection{Gunicorn: configuration}
In order to manage the gunicorn service we will use a script, which is in charge of:
\begin{itemize}
    \item Open the virtual environment, if used. If not, comment the line with \#
    \item Collect the static files.
    \item Start the web server.
\end{itemize}

In this guide we will use the following path/name for the mentioned script:
\begin{lstlisting}[language=Bash]
ipolDevel/gunicorn_start.sh
\end{lstlisting}

Open the script and configure the parameters:
\begin{itemize}
    \item NAME: Name of the application.
    \item DJANGODIR: Django project directory path (absolute).
    \item SOCKFILE: Gunicorn socket path (absolute).
    \item VENV: Virtual environment name (if used).
    \item USER, GROUP: User and group names, to run the server as. Both names must be valid at the current server.
    \item NUM\_WORKERS: Gunicorn worker processes number.
    \item DJANGO\_SETTINGS\_MODULE: Django settings name.
    \item DJANGO\_WSGI\_MODULE: Django WSGI module name.
    \item Gunicorn port number. In this guide we will use port 8001. Consider that this is NOT the port used to access the final site, because it will not serve the static files (DEBUG = False in settings.py). Another port will be configured in Nginx for that purpose.
    \item Finally, add execution permissions to the script.
\end{itemize}

\subsection{Gunicorn: management}
\begin{itemize}
    \item Start service by executing the script:
    \begin{lstlisting}[language=Bash]
    {prod} ~/ipolDevel$ ./gunicorn_start.sh
    \end{lstlisting}

    \item Stop service: Ctrl + C
\end{itemize}



\subsection{Accessing the Control Panel}
To access the Control Panel the users need to go to \url{http://ipolcore.ipol.im/cp/} and log in with their username and password.

\section{Docker}
A docker image is available to develop and run the IPOL demo system in any enviroment (say, Mac OS and others).

\paragraph{Usage}:
The necessary commands in order to work with docker will be described in the next section. The first thing you should do is
build the Docker image, then you will be able to create as many containers as you want. Then run the container and you
will have a terminal inside so you will be able to execute the terminal.py and bring up all modules. Nginx and ssh will be already
configured and running.

Once inside the container tty there will be a user called ipol wich should be used to execute any task related to modules, ipol terminal, 
cp or django. For sysadmin tasks that result in a change in the system imply that a change in the dockerfile is needed.
 
In order to run the Django server for the control panel you will have to make the migrations once per
container before actually running the server. For this purpose there is a script under the Docker folder called migrations\_cp.sh.
 After the migrations run the Django server as you would anywhere else: python manage.py runserver 127.0.0.1:8000.
 Every command should be executed inside ipolDevel.
 
 To improve usage of the docker container, some alias have been created to gain easy access to the terminal and to execute the control panel:
 \begin{itemize}
 	\item terminal: cd into the terminal directory and execute terminal.py
 	\item cp: cd into "ipol\_webapp" and execute "python manage.py runserver 127.0.0.1:8000" command
 \end{itemize}
 


\paragraph{Docker build}:\\
\begin{lstlisting}[firstnumber=1,breaklines]
  $ docker build ~/ipolDevel -t ipol -f ~/ipolDevel/docker/Dockerfile
\end{lstlisting}

With this command we will have docker create an image from the Dockerfile in the root of the project. It will go through the creation and configuration of the development envirorment. Explanation:
\begin{itemize}
  \item docker build: command to build an image
  \item {\tt \~{}/ipolDevel} : The context of the image. Should always be the root of the project IPOL.
  \item -t ipol: Tag the image with the name ipol to reference it later.
  \item -f: flag to specify a Dockerfile
  \item {\tt \~{}/ipolDevel/docker/Dockerfile}: Location of the Dockerfile defining the image.
\end{itemize}

\paragraph{Docker run}:\\
\begin{lstlisting}[firstnumber=1,breaklines]
  $ docker run -it -v $(pwd):/home/ipol/ipolDevel -p 80:80 -h docker --add-host docker:127.0.0.1 --name ipol ipol
\end{lstlisting}

This command will create a container and log us in the terminal. Explanation:
\begin{itemize}
  \item docker run: command to create a container
  \item -it: makes the container interactive and attaches to a tty or terminal.
  \item -v \$(pwd):/home/ipol/ipolDevel: Creates a volume to share the project folder between the container and the host machine.
  \item -p 80:80: exposes port 80 in the container and links it to port 80 in the host machine.
  \item -h docker: defines the container's hostname
  \item --add-host docker:127.0.0.1: adds an entry to /etc/hosts mapping 127.0.0.1 to the host
  \item -name ipol: assigns the name ipol to the container for future reference
  \item ipol: tells docker to run a container from the image "ipol"
\end{itemize}

After this command we will be inside the containers tty. This command should be used each time after a docker build is done,
otherwise if the container is already exists, it will have to be removed or attached to. The orders to control containers and images are:

\paragraph{Docker start}:\\
In order to start the already created container.
\begin{lstlisting}[firstnumber=1,breaklines]
  $ docker start -i ipol
\end{lstlisting}

\paragraph{Docker exec}:\\
In order to attach a new terminal to the container. Useful if you need more than one terminal access to the container.
\begin{lstlisting}[firstnumber=1,breaklines]
  $ docker exec -it ipol bash
\end{lstlisting}

\paragraph{Docker ps}:\\
In order to get information about all the created containers.
\begin{lstlisting}[firstnumber=1,breaklines]
  $ docker ps -a
\end{lstlisting}

\paragraph{Docker images}:\\
In order to get information about all the created images.
\begin{lstlisting}[firstnumber=1,breaklines]
  $ docker images
\end{lstlisting}

\paragraph{Docker rm}:\\
In order to remove a container. The id or name provided will be available doing "docker ps -a"
\begin{lstlisting}[firstnumber=1,breaklines]
  $ docker rm 'docker_image_id'
\end{lstlisting}

\paragraph{Docker rmi}:\\
In order to remove an image. The id or name provided will be available doing "docker images"
\begin{lstlisting}[firstnumber=1,breaklines]
  $ docker rmi 'docker_image_id'
\end{lstlisting}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Virtual Machines}
In order to allow members of the lab use the IPOL infrastructure for their computational research need, we create virtual machines (VM) with VirtualBox.

The VirtualBox package needs to be installed from the VirtualBox's repositories. First, add the GPG key:

{\tt sudo su -c 'wget -q -O- http://download.virtualbox.org/virtualbox/\
debian/oracle\_vbox\_2016.asc | apt-key add -'}

Then add the following line to {\tt /etc/apt/sources.list} (change \emph{stretch} to the codename of the current stable distribution):

{\tt deb http://download.virtualbox.org/virtualbox/debian stretch contrib}

The CPU priorities need to be added /etc/security/limits.conf:
\begin{verbatim}
*               soft     priority            17
ipol            soft     priority            0
\end{verbatim}


The following packages need to be installed with: sudo apt-get install virtualbox virtualbox-dkms virtualbox-guest-dkms virtualbox-guest-utils vde2 virtualbox-guest-additions-iso xfonts-100dpi xfonts-75dpi linux-headers-amd64 linux-image-amd64

Then the ``nosmap" kernel option need to be added to the kernel options: sudo nano /etc/default/grub

\begin{verbatim}
GRUB_CMDLINE_LINUX_DEFAULT="nosmap"
GRUB_CMDLINE_LINUX="nosmap"
\end{verbatim}

Running {\tt update-grub} is needed to update the boot entries. For example:

\begin{verbatim}
Found linux image: /boot/bzImage-3.14.32-xxxx-grs-ipv6-64
Found linux image: /boot/vmlinuz-3.16.0-4-amd64
Found initrd image: /boot/initrd.img-3.16.0-4-amd64
\end{verbatim}

In {\tt /etc/default/grub} we should configure {\tt GRUB\_DEFAULT=2} (index begins at 0) before.

Finally, reboot the machine.

To start and stop the virtual machine called ``VM":

{\tt VBoxManage startvm VM --type headless}

{\tt vboxmanage controlvm VM poweroff soft}

In case the VM is not stopped, the VirtualBox processes can be terminated: {\tt killall VBoxXPCOMIPCD VBoxSVC VBoxHeadless}

To avoid that the VM is not started after an eventual machine reboot, it is convenient to call a script to start the virtual machine. The following line needs to be added to the crontab (execute {\tt crontab -e}):

{\tt @reboot /home/vm/start\_vm.sh}

This script contains the instructions to start again the VM:

\begin{verbatim}
#!/bin/bash
VBoxManage startvm VM --type headless
\end{verbatim}

To allow the external users to access the virtual machine, we need to configure a port forwarding rule.
It can be done easily by running the virtual machine (with ssh -X ...) and in the VirtualBox: Settings / Network / Port Forwarding: protocol TCP, Host Post 2222, Guest Port 22.

\section{Troubleshooting}

\textbf{After a new release of Debian Stable the binaries of the methods of the demos no longer work}

Probably it is because the binaries where staticly compiled againts libraries whose versions are no longer installed in our servers. Remove the directory {\tt ipolDevel/ipol\_demo/modules/demorunner/binaries} of all the machines where a demoRunner module has been installed.
\vspace{0.5cm}


\textbf{Python fails to import libtiff}

It needs to generate a header in a directory at which only root can write. Thus, execute ipython as root and then execute {\tt import libtiff}. After this, non-privileged users will be able to import the library normally.
\vspace{0.5cm}

\textbf{After uploading a package Python complains about not being able to import a package because a system library is not at the correct version, even if I uninstall/install the package with {\tt pip}.}

Normally the reason is that pip is not managing the cache correctly and it is installing an old version of the package which needs an old version of the system library. Remove the pip cache: {\tt rm -rf /root/.cache/pip}.
\vspace{0.5cm}

\textbf{VirtualBox does not work.}
Check that you have installed the needed VirtualBox packages, specially the kernel module (virtualbox-guest-dkms).
If you have everything installed and it is still not working, then execute {\tt dpkg-reconfigure virtualbox-guest-dkms} to force the re-compilation of the kernel module.

If still does not work, then purge the packages and re-install:

\begin{verbatim}
apt-get purge virtualbox-dkms virtualbox-guest-dkms
apt-get install linux-headers-amd64 virtualbox-5.1
\end{verbatim}


\bibliographystyle{plain}
\bibliography{biblio}

\end{document}
% End of document
